# Snapshot Audit Report

**Host:** localhost  
**Date:** 2026-02-09 17:46:10  
**Audit Profile:** mipro-linux  
**Audit Score:** 80/100

## Key Metrics
- Disk usage (max): 6%
- Memory usage: 15%
- Load average (1m): 1.19
- Inactive services: 1

## Findings
- Inactive services: sshd
- SSH PermitRootLogin is enabled

## Module Outputs

- **System Information:** OK- **Service Status:** OK- **Security Baseline:** OK- **User Audit:** OK- **Authentication Audit:** OK- **Network Audit:** OK- **Time Sync:** OK- **Compliance (CIS):** OK- **NGINX Check:** MISSING- **Logs Collected:** OK- **Updates Status:** OK- **AI Analysis:** MISSING
## Detailed Output
### linux_base.txt
```
OS Info:
NAME="Ubuntu"
VERSION="24.04.3 LTS (Noble Numbat)"

Kernel: 6.8.0-94-generic

Uptime:  17:46:13 up 2 days,  4:31,  2 users,  load average: 1.21, 0.66, 0.30

CPU Info:
Architecture:                         x86_64
CPU(s):                               4
Model name:                           AMD EPYC Processor (with IBPB)

Memory:
               total        used        free      shared  buff/cache   available
Mem:           7.8Gi       1.2Gi       4.9Gi       1.3Mi       2.0Gi       6.6Gi
Swap:             0B          0B          0B

Disk:
Filesystem      Size  Used Avail Use% Mounted on
tmpfs           795M  1.2M  793M   1% /run
/dev/sda1        72G   24G   49G  33% /
tmpfs           3.9G  140K  3.9G   1% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
/dev/sda16      881M  117M  703M  15% /boot
/dev/sda15      105M  6.2M   99M   6% /boot/efi
tmpfs           795M   20K  795M   1% /run/user/0

Load Avg 1m: 1.19

Top CPU Processes:
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root       88748  100  0.3  39248 26880 ?        S    17:46   0:00 /usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1770655576.425513-88728-168461098158026/AnsiballZ_command.py
root       88728 25.5  0.6 151256 53744 ?        S    17:46   0:00 /usr/bin/python3 /usr/bin/ansible-playbook -i inventories/example.yml playbooks/snapshot.yml -e profile_file=/root/.openclaw/workspace/projects/ops-snapshot-audit/profiles/mipro-linux.yml -e ai_provider=google
root       88267 21.8  0.7 150408 61468 ?        Sl   17:46   0:02 /usr/bin/python3 /usr/bin/ansible-playbook -i inventories/example.yml playbooks/snapshot.yml -e profile_file=/root/.openclaw/workspace/projects/ops-snapshot-audit/profiles/mipro-linux.yml -e ai_provider=google
root       84914  9.7  0.6 110544 53616 pts/1    Sl+  17:43   0:19 /usr/lib/node_modules/@openai/codex/vendor/x86_64-unknown-linux-musl/codex/codex Continue developing RAG Factory. The project already has multi-format ingestion (PDF, DOCX, HTML, CSV, JSON, TXT, MD). Now add: 1) Vector store using LanceDB (already in requirements.txt), 2) Embedding generation (support both OpenAI and local sentence-transformers), 3) A CLI for querying documents (rag query "question"), 4) A simple retrieval function that returns relevant chunks. Keep it simple and production-ready. Work step by step.
root       75221  3.5  5.4 22600196 441008 ?     Ssl  14:47   6:17 openclaw-gateway
root       81041  1.6  0.7 112344 57268 pts/2    Sl+  16:51   0:52 /usr/lib/node_modules/@openai/codex/vendor/x86_64-unknown-linux-musl/codex/codex Improve the ops-snapshot-audit project to make it more valuable, intelligent, and production-ready. Consider adding new audit modules, better reporting, integration with monitoring systems, security scanning, compliance checks, anomaly detection, and any other features that would provide great utility. Make the project professional and robust. Work step by step, and output your progress.
root       86383  0.9  0.0      0     0 ?        I    17:44   0:00 [kworker/u8:6-loop9]
root       86384  0.7  0.0      0     0 ?        I    17:44   0:00 [kworker/u8:7-events_unbound]
root       81032  0.4  0.0  14076  5948 ?        Ss   16:51   0:13 tmux new-session -d -s codex-ops-audit codex "Improve the ops-snapshot-audit project to make it more valuable, intelligent, and production-ready. Consider adding new audit modules, better reporting, integration with monitoring systems, security scanning, compliance checks, anomaly detection, and any other features that would provide great utility. Make the project professional and robust. Work step by step, and output your progress."

Top Memory Processes:
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root       75221  3.5  5.4 22600196 441008 ?     Ssl  14:47   6:17 openclaw-gateway
root        1085  0.0  1.0 2061784 81900 ?       Ssl  Feb07   0:58 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
root         860  0.2  0.9 941524 77052 ?        Ssl  Feb07   7:16 /usr/bin/python3 /usr/bin/fail2ban-server -xf start
root         329  0.0  0.8 108784 70168 ?        S<s  Feb07   1:11 /usr/lib/systemd/systemd-journald
root       88267 21.8  0.7 150408 61468 ?        Sl   17:46   0:02 /usr/bin/python3 /usr/bin/ansible-playbook -i inventories/example.yml playbooks/snapshot.yml -e profile_file=/root/.openclaw/workspace/projects/ops-snapshot-audit/profiles/mipro-linux.yml -e ai_provider=google
root       81041  1.6  0.7 112344 57268 pts/2    Sl+  16:51   0:52 /usr/lib/node_modules/@openai/codex/vendor/x86_64-unknown-linux-musl/codex/codex Improve the ops-snapshot-audit project to make it more valuable, intelligent, and production-ready. Consider adding new audit modules, better reporting, integration with monitoring systems, security scanning, compliance checks, anomaly detection, and any other features that would provide great utility. Make the project professional and robust. Work step by step, and output your progress.
root       88759 18.1  0.6 152352 53892 ?        S    17:46   0:00 /usr/bin/python3 /usr/bin/ansible-playbook -i inventories/example.yml playbooks/snapshot.yml -e profile_file=/root/.openclaw/workspace/projects/ops-snapshot-audit/profiles/mipro-linux.yml -e ai_provider=google
root       84914  9.7  0.6 110544 53616 pts/1    Sl+  17:43   0:19 /usr/lib/node_modules/@openai/codex/vendor/x86_64-unknown-linux-musl/codex/codex Continue developing RAG Factory. The project already has multi-format ingestion (PDF, DOCX, HTML, CSV, JSON, TXT, MD). Now add: 1) Vector store using LanceDB (already in requirements.txt), 2) Embedding generation (support both OpenAI and local sentence-transformers), 3) A CLI for querying documents (rag query "question"), 4) A simple retrieval function that returns relevant chunks. Keep it simple and production-ready. Work step by step.
root         898  0.2  0.5 1940804 46840 ?       Ssl  Feb07   6:58 /usr/bin/containerd

Listening Ports:
Netid State  Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess                                                 
udp   UNCONN 0      0         127.0.0.54:53         0.0.0.0:*    users:(("systemd-resolve",pid=779,fd=16))              
udp   UNCONN 0      0      127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=779,fd=14))              
udp   UNCONN 0      0            0.0.0.0:5353       0.0.0.0:*    users:(("openclaw-gatewa",pid=75221,fd=36))            
udp   UNCONN 0      0            0.0.0.0:5353       0.0.0.0:*    users:(("openclaw-gatewa",pid=75221,fd=25))            
tcp   LISTEN 0      511        127.0.0.1:18792      0.0.0.0:*    users:(("openclaw-gatewa",pid=75221,fd=35))            
tcp   LISTEN 0      511        127.0.0.1:18789      0.0.0.0:*    users:(("openclaw-gatewa",pid=75221,fd=22))            
tcp   LISTEN 0      4096      127.0.0.54:53         0.0.0.0:*    users:(("systemd-resolve",pid=779,fd=17))              
tcp   LISTEN 0      4096         0.0.0.0:22         0.0.0.0:*    users:(("sshd",pid=1469,fd=3),("systemd",pid=1,fd=218))
tcp   LISTEN 0      4096         0.0.0.0:631        0.0.0.0:*    users:(("cupsd",pid=1208,fd=9))                        
tcp   LISTEN 0      4096   127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=779,fd=15))              
tcp   LISTEN 0      511            [::1]:18789         [::]:*    users:(("openclaw-gatewa",pid=75221,fd=23))            
tcp   LISTEN 0      4096            [::]:22            [::]:*    users:(("sshd",pid=1469,fd=4),("systemd",pid=1,fd=219))
tcp   LISTEN 0      4096            [::]:631           [::]:*    users:(("cupsd",pid=1208,fd=10))                       

ESET Status:
ESET not found

All Services:
  UNIT                                           LOAD      ACTIVE   SUB     DESCRIPTION
  apparmor.service                               loaded    active   exited  Load AppArmor profiles
  apport-autoreport.service                      loaded    inactive dead    Process error reports when automatic reporting is enabled
  apport.service                                 loaded    active   exited  automatic crash report generation
  apt-daily-upgrade.service                      loaded    inactive dead    Daily apt upgrade and clean activities
  apt-daily.service                              loaded    inactive dead    Daily apt download activities
● auditd.service                                 not-found inactive dead    auditd.service
  blk-availability.service                       loaded    active   exited  Availability of block devices
  cloud-config.service                           loaded    active   exited  Cloud-init: Config Stage
  cloud-final.service                            loaded    active   exited  Cloud-init: Final Stage
  cloud-init-hotplugd.service                    loaded    inactive dead    Cloud-init: Hotplug Hook
  cloud-init-local.service                       loaded    active   exited  Cloud-init: Local Stage (pre-network)
● cloud-init.service                             loaded    failed   failed  Cloud-init: Network Stage
● connman.service                                not-found inactive dead    connman.service
● console-screen.service                         not-found inactive dead    console-screen.service
  console-setup.service                          loaded    active   exited  Set console font and keymap
  containerd.service                             loaded    active   running containerd container runtime
  cron.service                                   loaded    active   running Regular background program processing daemon
  dbus.service                                   loaded    active   running D-Bus System Message Bus
● display-manager.service                        not-found inactive dead    display-manager.service
  dm-event.service                               loaded    inactive dead    Device-mapper event daemon
  dmesg.service                                  loaded    inactive dead    Save initial kernel messages after boot
  docker.service                                 loaded    active   running Docker Application Container Engine
  dpkg-db-backup.service                         loaded    inactive dead    Daily dpkg database backup service
  e2scrub_all.service                            loaded    inactive dead    Online ext4 Metadata Check for All Filesystems
  e2scrub_reap.service                           loaded    inactive dead    Remove Stale Online ext4 Metadata Check Snapshots
  emergency.service                              loaded    inactive dead    Emergency Shell
  fail2ban.service                               loaded    active   running Fail2Ban Service
● fcoe.service                                   not-found inactive dead    fcoe.service
  finalrd.service                                loaded    active   exited  Create final runtime dir for shutdown pivot root
● firewalld.service                              not-found inactive dead    firewalld.service
  fstrim.service                                 loaded    inactive dead    Discard unused blocks on filesystems from /etc/fstab
  fwupd-refresh.service                          loaded    inactive dead    Refresh fwupd metadata and update motd
  fwupd.service                                  loaded    active   running Firmware update daemon
  getty-static.service                           loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available
  getty@tty1.service                             loaded    active   running Getty on tty1
  grub-common.service                            loaded    inactive dead    Record successful boot for GRUB
  grub-initrd-fallback.service                   loaded    inactive dead    GRUB failed boot detection
● hv_kvp_daemon.service                          not-found inactive dead    hv_kvp_daemon.service
  initrd-cleanup.service                         loaded    inactive dead    Cleaning Up and Shutting Down Daemons
  initrd-parse-etc.service                       loaded    inactive dead    Mountpoints Configured in the Real Root
  initrd-switch-root.service                     loaded    inactive dead    Switch Root
  initrd-udevadm-cleanup-db.service              loaded    inactive dead    Cleanup udev Database
● ip6tables.service                              not-found inactive dead    ip6tables.service
● ipset.service                                  not-found inactive dead    ipset.service
● iptables.service                               not-found inactive dead    iptables.service
● iscsi-shutdown.service                         not-found inactive dead    iscsi-shutdown.service
  iscsid.service                                 loaded    inactive dead    iSCSI initiator daemon (iscsid)
● kbd.service                                    not-found inactive dead    kbd.service
  keyboard-setup.service                         loaded    active   exited  Set the console keyboard layout
  kmod-static-nodes.service                      loaded    active   exited  Create List of Static Device Nodes
  ldconfig.service                               loaded    inactive dead    Rebuild Dynamic Linker Cache
  logrotate.service                              loaded    inactive dead    Rotate log files
● lvm2-activation-early.service                  not-found inactive dead    lvm2-activation-early.service
  lvm2-lvmpolld.service                          loaded    inactive dead    LVM2 poll daemon
  lvm2-monitor.service                           loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
  man-db.service                                 loaded    inactive dead    Daily man-db regeneration
  ModemManager.service                           loaded    active   running Modem Manager
  modprobe@configfs.service                      loaded    inactive dead    Load Kernel Module configfs
  modprobe@dm_mod.service                        loaded    inactive dead    Load Kernel Module dm_mod
  modprobe@drm.service                           loaded    inactive dead    Load Kernel Module drm
  modprobe@efi_pstore.service                    loaded    inactive dead    Load Kernel Module efi_pstore
  modprobe@fuse.service                          loaded    inactive dead    Load Kernel Module fuse
  modprobe@loop.service                          loaded    inactive dead    Load Kernel Module loop
  motd-news.service                              loaded    inactive dead    Message of the Day
  multipathd.service                             loaded    active   running Device-Mapper Multipath Device Controller
  netplan-ovs-cleanup.service                    loaded    inactive dead    OpenVSwitch configuration for cleanup
  networkd-dispatcher.service                    loaded    inactive dead    Dispatcher daemon for systemd-networkd
● networking.service                             not-found inactive dead    networking.service
● NetworkManager.service                         not-found inactive dead    NetworkManager.service
  nftables.service                               loaded    inactive dead    nftables
  open-iscsi.service                             loaded    inactive dead    Login to default iSCSI targets
  open-vm-tools.service                          loaded    inactive dead    Service for virtual machines hosted on VMware
● ovsdb-server.service                           not-found inactive dead    ovsdb-server.service
  packagekit.service                             loaded    active   running PackageKit Daemon
  plymouth-quit-wait.service                     loaded    active   exited  Hold until boot process finishes up
  plymouth-quit.service                          loaded    active   exited  Terminate Plymouth Boot Screen
  plymouth-read-write.service                    loaded    active   exited  Tell Plymouth To Write Out Runtime Data
  plymouth-start.service                         loaded    inactive dead    Show Plymouth Boot Screen
  plymouth-switch-root.service                   loaded    inactive dead    Plymouth switch root service
  polkit.service                                 loaded    active   running Authorization Manager
  pollinate.service                              loaded    inactive dead    Pollinate to seed the pseudo random number generator
● rbdmap.service                                 not-found inactive dead    rbdmap.service
  rc-local.service                               loaded    inactive dead    /etc/rc.local Compatibility
  rescue.service                                 loaded    inactive dead    Rescue Shell
  rsyslog.service                                loaded    active   running System Logging Service
  secureboot-db.service                          loaded    inactive dead    Secure Boot updates for DB and DBX
  serial-getty@ttyS0.service                     loaded    active   running Serial Getty on ttyS0
  setvtrgb.service                               loaded    active   exited  Set console scheme
  snap.cups.cups-browsed.service                 loaded    active   running Service for snap application cups.cups-browsed
  snap.cups.cupsd.service                        loaded    active   running Service for snap application cups.cupsd
  snapd.apparmor.service                         loaded    active   exited  Load AppArmor profiles managed internally by snapd
  snapd.autoimport.service                       loaded    inactive dead    Auto import assertions from block devices
  snapd.core-fixup.service                       loaded    inactive dead    Automatically repair incorrect owner/permissions on core devices
  snapd.failure.service                          loaded    inactive dead    Failure handling of the snapd snap
  snapd.recovery-chooser-trigger.service         loaded    inactive dead    Wait for the Ubuntu Core chooser trigger
  snapd.seeded.service                           loaded    active   exited  Wait until snapd is fully seeded
  snapd.service                                  loaded    active   running Snap Daemon
  snapd.snap-repair.service                      loaded    inactive dead    Automatically fetch and run repair assertions
  snapd.system-shutdown.service                  loaded    inactive dead    Ubuntu core (all-snaps) system shutdown helper setup service
  ssh.service                                    loaded    active   running OpenBSD Secure Shell server
● sshd-keygen.service                            not-found inactive dead    sshd-keygen.service
● sshd.service                                   not-found inactive dead    sshd.service
  sysstat-collect.service                        loaded    inactive dead    system activity accounting tool
  sysstat-summary.service                        loaded    inactive dead    Generate a daily summary of process accounting
  sysstat.service                                loaded    active   exited  Resets System Activity Logs
  systemd-ask-password-console.service           loaded    inactive dead    Dispatch Password Requests to Console
  systemd-ask-password-plymouth.service          loaded    inactive dead    Forward Password Requests to Plymouth
  systemd-ask-password-wall.service              loaded    inactive dead    Forward Password Requests to Wall
  systemd-battery-check.service                  loaded    inactive dead    Check battery level during early boot
  systemd-binfmt.service                         loaded    active   exited  Set Up Additional Binary Formats
  systemd-bsod.service                           loaded    inactive dead    Displays emergency message in full screen.
  systemd-firstboot.service                      loaded    inactive dead    First Boot Wizard
  systemd-fsck-root.service                      loaded    inactive dead    File System Check on Root Device
  systemd-fsck@dev-disk-by\x2dlabel-BOOT.service loaded    active   exited  File System Check on /dev/disk/by-label/BOOT
  systemd-fsck@dev-disk-by\x2dlabel-UEFI.service loaded    active   exited  File System Check on /dev/disk/by-label/UEFI
  systemd-fsckd.service                          loaded    inactive dead    File System Check Daemon to report status
  systemd-hibernate-resume.service               loaded    inactive dead    Resume from hibernation
  systemd-hibernate.service                      loaded    inactive dead    System Hibernate
  systemd-hwdb-update.service                    loaded    inactive dead    Rebuild Hardware Database
  systemd-hybrid-sleep.service                   loaded    inactive dead    System Hybrid Suspend+Hibernate
  systemd-initctl.service                        loaded    inactive dead    initctl Compatibility Daemon
  systemd-journal-catalog-update.service         loaded    inactive dead    Rebuild Journal Catalog
  systemd-journal-flush.service                  loaded    active   exited  Flush Journal to Persistent Storage
  systemd-journald.service                       loaded    active   running Journal Service
  systemd-logind.service                         loaded    active   running User Login Management
  systemd-machine-id-commit.service              loaded    inactive dead    Commit a transient machine-id on disk
  systemd-modules-load.service                   loaded    active   exited  Load Kernel Modules
  systemd-networkd-wait-online.service           loaded    active   exited  Wait for Network to be Configured
  systemd-networkd.service                       loaded    active   running Network Configuration
● systemd-oomd.service                           not-found inactive dead    systemd-oomd.service
  systemd-pcrmachine.service                     loaded    inactive dead    TPM2 PCR Machine ID Measurement
  systemd-pcrphase-initrd.service                loaded    inactive dead    TPM2 PCR Barrier (initrd)
  systemd-pcrphase-sysinit.service               loaded    inactive dead    TPM2 PCR Barrier (Initialization)
  systemd-pcrphase.service                       loaded    inactive dead    TPM2 PCR Barrier (User)
  systemd-pstore.service                         loaded    inactive dead    Platform Persistent Storage Archival
  systemd-quotacheck.service                     loaded    inactive dead    File System Quota Check
  systemd-random-seed.service                    loaded    active   exited  Load/Save OS Random Seed
  systemd-remount-fs.service                     loaded    active   exited  Remount Root and Kernel File Systems
  systemd-repart.service                         loaded    inactive dead    Repartition Root Disk
  systemd-resolved.service                       loaded    active   running Network Name Resolution
  systemd-rfkill.service                         loaded    inactive dead    Load/Save RF Kill Switch Status
  systemd-soft-reboot.service                    loaded    inactive dead    Reboot System Userspace
  systemd-suspend-then-hibernate.service         loaded    inactive dead    System Suspend then Hibernate
  systemd-suspend.service                        loaded    inactive dead    System Suspend
  systemd-sysctl.service                         loaded    active   exited  Apply Kernel Variables
  systemd-sysext.service                         loaded    inactive dead    Merge System Extension Images into /usr/ and /opt/
  systemd-sysusers.service                       loaded    inactive dead    Create System Users
  systemd-timesyncd.service                      loaded    active   running Network Time Synchronization
  systemd-tmpfiles-clean.service                 loaded    inactive dead    Cleanup of Temporary Directories
  systemd-tmpfiles-setup-dev-early.service       loaded    active   exited  Create Static Device Nodes in /dev gracefully
  systemd-tmpfiles-setup-dev.service             loaded    active   exited  Create Static Device Nodes in /dev
  systemd-tmpfiles-setup.service                 loaded    active   exited  Create Volatile Files and Directories
  systemd-tpm2-setup-early.service               loaded    inactive dead    TPM2 SRK Setup (Early)
  systemd-tpm2-setup.service                     loaded    inactive dead    TPM2 SRK Setup
  systemd-udev-settle.service                    loaded    inactive dead    Wait for udev To Complete Device Initialization
  systemd-udev-trigger.service                   loaded    active   exited  Coldplug All udev Devices
  systemd-udevd.service                          loaded    active   running Rule-based Manager for Device Events and Files
  systemd-update-done.service                    loaded    inactive dead    Update is Completed
  systemd-update-utmp-runlevel.service           loaded    inactive dead    Record Runlevel Change in UTMP
  systemd-update-utmp.service                    loaded    active   exited  Record System Boot/Shutdown in UTMP
  systemd-user-sessions.service                  loaded    active   exited  Permit User Sessions
● systemd-vconsole-setup.service                 not-found inactive dead    systemd-vconsole-setup.service
  tpm-udev.service                               loaded    inactive dead    Handle dynamically added tpm devices
● ua-auto-attach.service                         not-found inactive dead    ua-auto-attach.service
  ua-reboot-cmds.service                         loaded    inactive dead    Ubuntu Pro reboot cmds
  ua-timer.service                               loaded    inactive dead    Ubuntu Pro Timer for running repeated jobs
● ubuntu-advantage-cloud-id-shim.service         not-found inactive dead    ubuntu-advantage-cloud-id-shim.service
  ubuntu-advantage.service                       loaded    inactive dead    Ubuntu Pro Background Auto Attach
  udisks2.service                                loaded    active   running Disk Manager
  ufw.service                                    loaded    active   exited  Uncomplicated firewall
  unattended-upgrades.service                    loaded    active   running Unattended Upgrades Shutdown
  update-notifier-download.service               loaded    inactive dead    Download data for packages that failed at package install time
  update-notifier-motd.service                   loaded    inactive dead    Check to see whether there is a new version of Ubuntu available
  user-runtime-dir@0.service                     loaded    active   exited  User Runtime Directory /run/user/0
  user@0.service                                 loaded    active   running User Manager for UID 0
  uuidd.service                                  loaded    inactive dead    Daemon for generating UUIDs
  vgauth.service                                 loaded    inactive dead    Authentication service for virtual machines hosted on VMware
● zfs-mount.service                              not-found inactive dead    zfs-mount.service

Legend: LOAD   → Reflects whether the unit definition was properly loaded.
        ACTIVE → The high-level unit activation state, i.e. generalization of SUB.
        SUB    → The low-level unit activation state, values depend on unit type.

178 loaded units listed.
To show all installed unit files use 'systemctl list-unit-files'.

```
### systemd_checks.txt
```
Service: sshd - Status: inactive
Service: cron - Status: active
```
### security_baseline.txt
```
=== SSHD Effective Config ===


=== SSHD Config File ===
PermitRootLogin yes

=== Critical File Permissions ===
644 /etc/passwd
644 /etc/group
640 /etc/shadow

=== Password Policy ===
PASS_MAX_DAYS	99999
PASS_MIN_DAYS	0
PASS_WARN_AGE	7

=== SUID/SGID Count ===
20

=== SUID/SGID Sample ===
/usr/bin/newgrp
/usr/bin/crontab
/usr/bin/chsh
/usr/bin/gpasswd
/usr/bin/sudo
/usr/bin/ssh-agent
/usr/bin/passwd
/usr/bin/su
/usr/bin/chage
/usr/bin/expiry
/usr/bin/fusermount3
/usr/bin/umount
/usr/bin/mount
/usr/bin/chfn
/usr/sbin/pam_extrausers_chkpwd
/usr/sbin/unix_chkpwd
/usr/lib/polkit-1/polkit-agent-helper-1
/usr/lib/openssh/ssh-keysign
/usr/lib/x86_64-linux-gnu/utempter/utempter
/usr/lib/dbus-1.0/dbus-daemon-launch-helper

=== World-Writable Count ===
22

=== World-Writable Sample ===
/tmp
/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-fwupd.service-Tjct6j/tmp
/tmp/snap-private-tmp/snap.cups/tmp
/tmp/.XIM-unix
/tmp/.ICE-unix
/tmp/.font-unix
/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-systemd-resolved.service-1W8VSA/tmp
/tmp/.X11-unix
/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-systemd-logind.service-SVMTOS/tmp
/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-polkit.service-qKyv1c/tmp
/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-systemd-timesyncd.service-aF17qo/tmp
/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-ModemManager.service-YLkpJH/tmp
/var/snap/cups/1142/tmp
/var/tmp
/var/tmp/cloud-init
/var/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-systemd-resolved.service-f36ktl/tmp
/var/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-systemd-logind.service-hpNPmV/tmp
/var/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-polkit.service-xwrM7C/tmp
/var/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-systemd-timesyncd.service-Otj7dz/tmp
/var/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-fwupd.service-jJj5vT/tmp
/var/tmp/systemd-private-467ed8573aec4173a6cdb822dcbf8b32-ModemManager.service-3zpRcN/tmp
/var/crash

=== Security Findings ===
SSH PermitRootLogin is enabled

```
### user_audit.txt
```
=== Local Users (uid >= 1000) ===
erne:1000:/bin/bash
gaby:1001:/bin/bash
snapd-range-524288-root:524288:/usr/bin/false
snap_daemon:584788:/usr/bin/false

=== System Users (uid < 1000) ===
root:0:/bin/bash
daemon:1:/usr/sbin/nologin
bin:2:/usr/sbin/nologin
sys:3:/usr/sbin/nologin
sync:4:/bin/sync
games:5:/usr/sbin/nologin
man:6:/usr/sbin/nologin
lp:7:/usr/sbin/nologin
mail:8:/usr/sbin/nologin
news:9:/usr/sbin/nologin
uucp:10:/usr/sbin/nologin
proxy:13:/usr/sbin/nologin
www-data:33:/usr/sbin/nologin
backup:34:/usr/sbin/nologin
list:38:/usr/sbin/nologin
irc:39:/usr/sbin/nologin
_apt:42:/usr/sbin/nologin
systemd-network:998:/usr/sbin/nologin
systemd-timesync:996:/usr/sbin/nologin
dhcpcd:100:/bin/false
messagebus:101:/usr/sbin/nologin
syslog:102:/usr/sbin/nologin
systemd-resolve:991:/usr/sbin/nologin
uuidd:103:/usr/sbin/nologin
tss:104:/bin/false
sshd:105:/usr/sbin/nologin
pollinate:106:/bin/false
tcpdump:107:/usr/sbin/nologin
landscape:108:/usr/sbin/nologin
fwupd-refresh:990:/usr/sbin/nologin
polkitd:989:/usr/sbin/nologin

=== Groups (sample) ===
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:erne,gaby
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:erne,gaby
nogroup:x:65534:
systemd-journal:x:999:
systemd-network:x:998:
crontab:x:997:
systemd-timesync:x:996:
input:x:995:
sgx:x:994:
kvm:x:993:
render:x:992:
messagebus:x:101:
syslog:x:102:
systemd-resolve:x:991:
uuidd:x:103:
tss:x:104:
lxd:x:105:
_ssh:x:106:
rdma:x:107:
tcpdump:x:108:
landscape:x:109:
fwupd-refresh:x:990:
polkitd:x:989:
admin:x:110:
netdev:x:111:
erne:x:1000:
gaby:x:1001:
docker:x:988:
snapd-range-524288-root:x:524288:
snap_daemon:x:584788:

=== Recent Logins ===
root     pts/1        tmux(81032).%1   Mon Feb  9 17:43   still logged in
root     pts/2        tmux(81032).%0   Mon Feb  9 16:51   still logged in
root     pts/2        tmux(76790).%0   Mon Feb  9 15:43 - 16:44  (01:00)
root     pts/1        86.127.228.85    Mon Feb  9 14:17 - 16:51  (02:34)
root     pts/0        86.127.228.85    Mon Feb  9 13:55   still logged in
root     pts/0        86.127.228.85    Mon Feb  9 01:25 - 04:50  (03:25)
root     pts/0        86.127.228.85    Sun Feb  8 18:05 - 20:22  (02:17)
reboot   system boot  6.8.0-94-generic Sat Feb  7 13:15   still running
root     pts/1        86.127.228.85    Sat Feb  7 03:09 - 04:54  (01:44)
root     pts/1        86.127.228.85    Fri Feb  6 13:06 - 15:20  (02:14)
root     pts/1        86.127.228.85    Fri Feb  6 01:54 - 04:47  (02:52)
root     pts/1        86.127.228.85    Thu Feb  5 01:31 - 03:47  (02:15)
root     pts/3        18.135.20.40     Wed Feb  4 21:02 - 00:14  (03:11)
root     pts/3        86.127.228.85    Wed Feb  4 15:57 - 20:14  (04:17)
root     pts/0        tmux(126587).%1  Wed Feb  4 12:18 - down  (3+00:56)
root     pts/2        tmux(126587).%0  Wed Feb  4 12:18 - down  (3+00:56)
root     pts/1        86.127.228.85    Wed Feb  4 11:39 - 23:13  (11:33)
root     pts/3        tmux(100020).%1  Wed Feb  4 04:37 - 12:18  (07:40)
root     pts/0        tmux(100020).%0  Wed Feb  4 04:37 - 12:18  (07:40)
root     pts/2        tmux(99517).%1   Wed Feb  4 04:36 - 04:37  (00:01)
root     pts/0        tmux(99517).%0   Wed Feb  4 04:36 - 04:37  (00:01)
root     pts/0        tmux(89563).%0   Wed Feb  4 00:03 - 00:04  (00:00)
root     pts/1        86.127.228.85    Tue Feb  3 22:00 - 06:59  (08:58)
root     pts/0        86.127.228.85    Tue Feb  3 21:27 - 22:25  (00:57)
root     pts/0        86.127.228.85    Mon Feb  2 15:46 - 15:47  (00:01)
root     pts/2        86.127.228.85    Mon Feb  2 12:54 - 15:44  (02:49)
root     pts/1        86.127.228.85    Mon Feb  2 12:24 - 15:45  (03:21)
root     pts/1        86.127.228.85    Mon Feb  2 12:17 - 12:24  (00:06)
root     pts/1        86.127.228.85    Mon Feb  2 12:14 - 12:17  (00:02)
root     pts/0        86.127.228.85    Mon Feb  2 09:01 - 13:15  (04:14)
root     pts/1        86.127.228.85    Sun Feb  1 13:44 - 15:59  (02:14)
root     pts/0        86.127.228.85    Sun Feb  1 13:44 - 08:44  (19:00)
root     pts/1        86.127.228.75    Sat Jan 31 22:51 - 01:04  (02:12)
root     pts/0        86.127.228.75    Sat Jan 31 22:49 - 02:18  (03:29)
reboot   system boot  6.8.0-90-generic Sat Jan 31 22:45 - 13:14 (6+14:29)

wtmp begins Sat Jan 31 22:45:16 2026

```
### auth_audit.txt
```
=== Auth Log Path ===
/var/log/auth.log

=== Auth Log Tail ===
2026-02-09T17:42:13.592329+01:00 vmi2763474 sshd[84846]: Received disconnect from 23.236.169.187 port 39892:11: Bye Bye [preauth]
2026-02-09T17:42:13.594223+01:00 vmi2763474 sshd[84846]: Disconnected from invalid user shivam 23.236.169.187 port 39892 [preauth]
2026-02-09T17:42:34.833191+01:00 vmi2763474 sshd[84872]: Invalid user node from 80.94.92.186 port 55572
2026-02-09T17:42:35.014115+01:00 vmi2763474 sshd[84872]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:42:35.014653+01:00 vmi2763474 sshd[84872]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=80.94.92.186 
2026-02-09T17:42:36.667565+01:00 vmi2763474 sshd[84872]: Failed password for invalid user node from 80.94.92.186 port 55572 ssh2
2026-02-09T17:42:54.006688+01:00 vmi2763474 sshd[84898]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=23.236.169.187  user=root
2026-02-09T17:42:55.797971+01:00 vmi2763474 sshd[84898]: Failed password for root from 23.236.169.187 port 55648 ssh2
2026-02-09T17:42:56.236444+01:00 vmi2763474 sshd[84898]: Received disconnect from 23.236.169.187 port 55648:11: Bye Bye [preauth]
2026-02-09T17:42:56.236714+01:00 vmi2763474 sshd[84898]: Disconnected from authenticating user root 23.236.169.187 port 55648 [preauth]
2026-02-09T17:43:03.018017+01:00 vmi2763474 sshd[84915]: Invalid user test from 103.124.92.110 port 42264
2026-02-09T17:43:03.025594+01:00 vmi2763474 sshd[84915]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:43:03.025806+01:00 vmi2763474 sshd[84915]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=103.124.92.110 
2026-02-09T17:43:05.525445+01:00 vmi2763474 sshd[84915]: Failed password for invalid user test from 103.124.92.110 port 42264 ssh2
2026-02-09T17:43:07.302246+01:00 vmi2763474 sshd[85038]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=101.36.107.233  user=root
2026-02-09T17:43:07.596073+01:00 vmi2763474 sshd[84915]: Received disconnect from 103.124.92.110 port 42264:11: Bye Bye [preauth]
2026-02-09T17:43:07.596384+01:00 vmi2763474 sshd[84915]: Disconnected from invalid user test 103.124.92.110 port 42264 [preauth]
2026-02-09T17:43:09.012686+01:00 vmi2763474 sshd[85038]: Failed password for root from 101.36.107.233 port 22216 ssh2
2026-02-09T17:43:09.578646+01:00 vmi2763474 sshd[85038]: Received disconnect from 101.36.107.233 port 22216:11: Bye Bye [preauth]
2026-02-09T17:43:09.578868+01:00 vmi2763474 sshd[85038]: Disconnected from authenticating user root 101.36.107.233 port 22216 [preauth]
2026-02-09T17:43:25.292692+01:00 vmi2763474 sshd[85608]: Invalid user auser from 14.103.112.56 port 50830
2026-02-09T17:43:25.307497+01:00 vmi2763474 sshd[85608]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:43:25.308012+01:00 vmi2763474 sshd[85608]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=14.103.112.56 
2026-02-09T17:43:27.162078+01:00 vmi2763474 sshd[85608]: Failed password for invalid user auser from 14.103.112.56 port 50830 ssh2
2026-02-09T17:43:27.565417+01:00 vmi2763474 sshd[85608]: Received disconnect from 14.103.112.56 port 50830:11: Bye Bye [preauth]
2026-02-09T17:43:27.565662+01:00 vmi2763474 sshd[85608]: Disconnected from invalid user auser 14.103.112.56 port 50830 [preauth]
2026-02-09T17:43:42.791475+01:00 vmi2763474 sshd[85836]: Invalid user jtribino from 23.236.169.187 port 43180
2026-02-09T17:43:42.801701+01:00 vmi2763474 sshd[85836]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:43:42.803884+01:00 vmi2763474 sshd[85836]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=23.236.169.187 
2026-02-09T17:43:44.985342+01:00 vmi2763474 sshd[85836]: Failed password for invalid user jtribino from 23.236.169.187 port 43180 ssh2
2026-02-09T17:43:52.253762+01:00 vmi2763474 sshd[85948]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=101.36.107.233  user=root
2026-02-09T17:43:54.475310+01:00 vmi2763474 sshd[85948]: Failed password for root from 101.36.107.233 port 37374 ssh2
2026-02-09T17:43:56.642278+01:00 vmi2763474 sshd[85948]: Received disconnect from 101.36.107.233 port 37374:11: Bye Bye [preauth]
2026-02-09T17:43:56.642807+01:00 vmi2763474 sshd[85948]: Disconnected from authenticating user root 101.36.107.233 port 37374 [preauth]
2026-02-09T17:44:03.179892+01:00 vmi2763474 sshd[86092]: Invalid user ai from 188.166.181.23 port 35840
2026-02-09T17:44:03.189976+01:00 vmi2763474 sshd[86092]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:44:03.193578+01:00 vmi2763474 sshd[86092]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=188.166.181.23 
2026-02-09T17:44:05.257652+01:00 vmi2763474 sshd[86092]: Failed password for invalid user ai from 188.166.181.23 port 35840 ssh2
2026-02-09T17:44:06.246688+01:00 vmi2763474 sshd[86092]: Received disconnect from 188.166.181.23 port 35840:11: Bye Bye [preauth]
2026-02-09T17:44:06.247153+01:00 vmi2763474 sshd[86092]: Disconnected from invalid user ai 188.166.181.23 port 35840 [preauth]
2026-02-09T17:44:19.445308+01:00 vmi2763474 sshd[86204]: Invalid user ubuntu from 14.63.196.175 port 51044
2026-02-09T17:44:19.449098+01:00 vmi2763474 sshd[86204]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:44:19.449313+01:00 vmi2763474 sshd[86204]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=14.63.196.175 
2026-02-09T17:44:21.382988+01:00 vmi2763474 sshd[86204]: Failed password for invalid user ubuntu from 14.63.196.175 port 51044 ssh2
2026-02-09T17:44:23.375400+01:00 vmi2763474 sshd[86204]: Received disconnect from 14.63.196.175 port 51044:11: Bye Bye [preauth]
2026-02-09T17:44:23.375719+01:00 vmi2763474 sshd[86204]: Disconnected from invalid user ubuntu 14.63.196.175 port 51044 [preauth]
2026-02-09T17:44:33.747375+01:00 vmi2763474 sshd[86251]: Invalid user ubuntu from 14.63.196.175 port 35262
2026-02-09T17:44:33.761943+01:00 vmi2763474 sshd[86251]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:44:33.762235+01:00 vmi2763474 sshd[86251]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=14.63.196.175 
2026-02-09T17:44:36.283743+01:00 vmi2763474 sshd[86251]: Failed password for invalid user ubuntu from 14.63.196.175 port 35262 ssh2
2026-02-09T17:44:37.628311+01:00 vmi2763474 sshd[86343]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=101.36.107.233  user=root
2026-02-09T17:44:38.435774+01:00 vmi2763474 sshd[86251]: Received disconnect from 14.63.196.175 port 35262:11: Bye Bye [preauth]
2026-02-09T17:44:38.436052+01:00 vmi2763474 sshd[86251]: Disconnected from invalid user ubuntu 14.63.196.175 port 35262 [preauth]
2026-02-09T17:44:39.698487+01:00 vmi2763474 sshd[86343]: Failed password for root from 101.36.107.233 port 52540 ssh2
2026-02-09T17:44:42.065080+01:00 vmi2763474 sshd[86343]: Received disconnect from 101.36.107.233 port 52540:11: Bye Bye [preauth]
2026-02-09T17:44:42.066174+01:00 vmi2763474 sshd[86343]: Disconnected from authenticating user root 101.36.107.233 port 52540 [preauth]
2026-02-09T17:45:01.037205+01:00 vmi2763474 CRON[87209]: pam_unix(cron:session): session opened for user root(uid=0) by root(uid=0)
2026-02-09T17:45:01.044349+01:00 vmi2763474 CRON[87209]: pam_unix(cron:session): session closed for user root
2026-02-09T17:45:21.170852+01:00 vmi2763474 sshd[87322]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=101.36.107.233  user=root
2026-02-09T17:45:23.279160+01:00 vmi2763474 sshd[87322]: Failed password for root from 101.36.107.233 port 12702 ssh2
2026-02-09T17:45:25.580955+01:00 vmi2763474 sshd[87322]: Received disconnect from 101.36.107.233 port 12702:11: Bye Bye [preauth]
2026-02-09T17:45:25.581316+01:00 vmi2763474 sshd[87322]: Disconnected from authenticating user root 101.36.107.233 port 12702 [preauth]
2026-02-09T17:45:38.910744+01:00 vmi2763474 sshd[87467]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=37.60.225.54  user=root
2026-02-09T17:45:38.945203+01:00 vmi2763474 sshd[87465]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=37.60.225.54  user=root
2026-02-09T17:45:38.958696+01:00 vmi2763474 sshd[87471]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=37.60.225.54  user=root
2026-02-09T17:45:38.960204+01:00 vmi2763474 sshd[87466]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=37.60.225.54  user=root
2026-02-09T17:45:40.687164+01:00 vmi2763474 sshd[87467]: Failed password for root from 37.60.225.54 port 57596 ssh2
2026-02-09T17:45:40.722070+01:00 vmi2763474 sshd[87465]: Failed password for root from 37.60.225.54 port 57572 ssh2
2026-02-09T17:45:40.737453+01:00 vmi2763474 sshd[87471]: Failed password for root from 37.60.225.54 port 57618 ssh2
2026-02-09T17:45:40.738376+01:00 vmi2763474 sshd[87466]: Failed password for root from 37.60.225.54 port 57584 ssh2
2026-02-09T17:45:41.069183+01:00 vmi2763474 sshd[87465]: Connection closed by authenticating user root 37.60.225.54 port 57572 [preauth]
2026-02-09T17:45:41.082498+01:00 vmi2763474 sshd[87467]: Connection closed by authenticating user root 37.60.225.54 port 57596 [preauth]
2026-02-09T17:45:41.134540+01:00 vmi2763474 sshd[87466]: Connection closed by authenticating user root 37.60.225.54 port 57584 [preauth]
2026-02-09T17:45:41.138700+01:00 vmi2763474 sshd[87471]: Connection closed by authenticating user root 37.60.225.54 port 57618 [preauth]
2026-02-09T17:45:42.296115+01:00 vmi2763474 sshd[87649]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=91.92.199.36  user=root
2026-02-09T17:45:44.618768+01:00 vmi2763474 sshd[87649]: Failed password for root from 91.92.199.36 port 35634 ssh2
2026-02-09T17:45:46.562893+01:00 vmi2763474 sshd[87649]: Received disconnect from 91.92.199.36 port 35634:11: Bye Bye [preauth]
2026-02-09T17:45:46.563435+01:00 vmi2763474 sshd[87649]: Disconnected from authenticating user root 91.92.199.36 port 35634 [preauth]
2026-02-09T17:46:03.574818+01:00 vmi2763474 sshd[88208]: Invalid user taibabi from 101.36.107.233 port 27868
2026-02-09T17:46:03.582195+01:00 vmi2763474 sshd[88208]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:46:03.582459+01:00 vmi2763474 sshd[88208]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=101.36.107.233 
2026-02-09T17:46:05.788564+01:00 vmi2763474 sshd[88208]: Failed password for invalid user taibabi from 101.36.107.233 port 27868 ssh2
2026-02-09T17:46:26.020805+01:00 vmi2763474 sshd[89184]: Invalid user user from 91.92.199.36 port 52192
2026-02-09T17:46:26.027684+01:00 vmi2763474 sshd[89184]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:46:26.027912+01:00 vmi2763474 sshd[89184]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=91.92.199.36 
2026-02-09T17:46:28.059709+01:00 vmi2763474 sshd[89184]: Failed password for invalid user user from 91.92.199.36 port 52192 ssh2
2026-02-09T17:46:28.144501+01:00 vmi2763474 sshd[89184]: Received disconnect from 91.92.199.36 port 52192:11: Bye Bye [preauth]
2026-02-09T17:46:28.144749+01:00 vmi2763474 sshd[89184]: Disconnected from invalid user user 91.92.199.36 port 52192 [preauth]
2026-02-09T17:46:32.388041+01:00 vmi2763474 sshd[89189]: Connection closed by 81.177.101.45 port 41214
2026-02-09T17:46:40.924081+01:00 vmi2763474 sshd[89190]: Invalid user zj from 81.177.101.45 port 41568
2026-02-09T17:46:42.187812+01:00 vmi2763474 sshd[89190]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:46:42.188027+01:00 vmi2763474 sshd[89190]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=81.177.101.45 
2026-02-09T17:46:43.748631+01:00 vmi2763474 sshd[89190]: Failed password for invalid user zj from 81.177.101.45 port 41568 ssh2
2026-02-09T17:46:45.241514+01:00 vmi2763474 sshd[89195]: Invalid user shivam from 94.103.3.8 port 46056
2026-02-09T17:46:45.246298+01:00 vmi2763474 sshd[89195]: pam_unix(sshd:auth): check pass; user unknown
2026-02-09T17:46:45.246511+01:00 vmi2763474 sshd[89195]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=94.103.3.8 
2026-02-09T17:46:47.238550+01:00 vmi2763474 sshd[89190]: Connection closed by invalid user zj 81.177.101.45 port 41568 [preauth]
2026-02-09T17:46:47.555946+01:00 vmi2763474 sshd[89195]: Failed password for invalid user shivam from 94.103.3.8 port 46056 ssh2
2026-02-09T17:46:48.034989+01:00 vmi2763474 sshd[89195]: Received disconnect from 94.103.3.8 port 46056:11: Bye Bye [preauth]
2026-02-09T17:46:48.035539+01:00 vmi2763474 sshd[89195]: Disconnected from invalid user shivam 94.103.3.8 port 46056 [preauth]

```
### network_audit.txt
```
=== IP Addresses ===
lo               UNKNOWN        127.0.0.1/8 ::1/128 
eth0             UP             178.18.253.157/20 2a02:c207:2276:3474::1/64 fe80::250:56ff:fe5c:80c1/64 
docker0          DOWN           172.17.0.1/16 

=== Routes ===
default via 178.18.240.1 dev eth0 proto static 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
178.18.240.0/20 via 178.18.240.1 dev eth0 

=== DNS ===
# This is /run/systemd/resolve/stub-resolv.conf managed by man:systemd-resolved(8).
# Do not edit.
#
# This file might be symlinked as /etc/resolv.conf. If you're looking at
# /etc/resolv.conf and seeing this text, you have followed the symlink.
#
# This is a dynamic resolv.conf file for connecting local clients to the
# internal DNS stub resolver of systemd-resolved. This file lists all
# configured search domains.
#
# Run "resolvectl status" to see details about the uplink DNS servers
# currently in use.
#
# Third party programs should typically not access this file directly, but only
# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a
# different way, replace this symlink by a static file or a different symlink.
#
# See man:systemd-resolved.service(8) for details about the supported modes of
# operation for /etc/resolv.conf.

nameserver 127.0.0.53
options edns0 trust-ad
search .

=== Firewall (UFW) ===


=== Firewall (firewalld) ===


=== Firewall Rules (iptables sample) ===


=== Firewall Rules (nft sample) ===

```
### time_sync.txt
```
=== Timedatectl ===
               Local time: Mon 2026-02-09 17:47:15 CET
           Universal time: Mon 2026-02-09 16:47:15 UTC
                 RTC time: Mon 2026-02-09 16:47:16
                Time zone: Europe/Berlin (CET, +0100)
System clock synchronized: yes
              NTP service: active
          RTC in local TZ: no

=== Chrony ===


=== NTP ===

```
### compliance_cis.txt
```
=== SSH Effective Config ===


=== Password Policy (login.defs) ===
PASS_MAX_DAYS=99999
PASS_MIN_DAYS=0
PASS_WARN_AGE=7

=== Sysctl Hardening ===


=== Compliance Findings ===
No compliance findings detected.

```
### nginx.txt - NOT FOUND
### logs_collect.txt
```
=== /var/log/syslog (last 50 lines) ===
2026-02-09T17:46:22.082758+01:00 vmi2763474 python3[89003]: ansible-ansible.legacy.command Invoked with executable=/bin/bash _raw_params=cat << 'EOF'#012Service: sshd - Status: inactive#012Service: cron - Status: active#012EOF#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None creates=None removes=None stdin=None
2026-02-09T17:46:22.839163+01:00 vmi2763474 python3[89034]: ansible-ansible.legacy.stat Invoked with path=output/localhost/2026-02-09/systemd_checks.txt follow=False get_checksum=True checksum_algorithm=sha1 get_mime=True get_attributes=True
2026-02-09T17:46:23.206795+01:00 vmi2763474 python3[89046]: ansible-ansible.legacy.copy Invoked with dest=output/localhost/2026-02-09/systemd_checks.txt mode=0644 src=/root/.ansible/tmp/ansible-tmp-1770655582.4960947-89013-55353616549670/source _original_basename=tmp51py6gsb follow=False checksum=71467f6f5f4c477b2ff7615fdf2da8607a09163d backup=False force=True unsafe_writes=False content=NOT_LOGGING_PARAMETER validate=None directory_mode=None remote_src=None local_follow=None owner=None group=None seuser=None serole=None selevel=None setype=None attributes=None
2026-02-09T17:46:23.743265+01:00 vmi2763474 python3[89071]: ansible-ansible.legacy.command Invoked with _raw_params=sshd -T 2>/dev/null | grep -E '^(permitrootlogin|passwordauthentication|pubkeyauthentication|permitemptypasswords)' _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:46:24.202642+01:00 vmi2763474 python3[89100]: ansible-ansible.legacy.command Invoked with _raw_params=grep -E '^(PermitRootLogin|PasswordAuthentication|PubkeyAuthentication|PermitEmptyPasswords)' /etc/ssh/sshd_config 2>/dev/null || true#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:46:24.687466+01:00 vmi2763474 python3[89127]: ansible-ansible.legacy.command Invoked with _raw_params=stat -c '%a %n' /etc/passwd /etc/group /etc/shadow 2>/dev/null || true#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:46:25.360770+01:00 vmi2763474 python3[89154]: ansible-ansible.legacy.command Invoked with _raw_params=grep -E '^(PASS_MAX_DAYS|PASS_MIN_DAYS|PASS_WARN_AGE)' /etc/login.defs 2>/dev/null || true#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:46:25.906895+01:00 vmi2763474 python3[89183]: ansible-ansible.legacy.command Invoked with _raw_params=find / -xdev -type f \( -perm -4000 -o -perm -2000 \) 2>/dev/null | wc -l#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:46:39.203012+01:00 vmi2763474 kernel: [UFW BLOCK] IN=eth0 OUT= MAC=00:50:56:5c:80:c1:c0:69:11:cd:0e:db:08:00 SRC=1.18.133.0 DST=178.18.253.157 LEN=61 TOS=0x00 PREC=0x00 TTL=20 ID=0 PROTO=UDP SPT=60582 DPT=53 LEN=41 
2026-02-09T17:46:56.961479+01:00 vmi2763474 python3[89224]: ansible-ansible.legacy.command Invoked with _raw_params=find / -xdev -type f \( -perm -4000 -o -perm -2000 \) 2>/dev/null | head -n 50#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:46:58.497694+01:00 vmi2763474 kernel: [UFW BLOCK] IN=eth0 OUT= MAC=00:50:56:5c:80:c1:c0:69:11:cd:0e:db:08:00 SRC=2.16.117.18 DST=178.18.253.157 LEN=62 TOS=0x00 PREC=0x00 TTL=20 ID=0 PROTO=UDP SPT=62031 DPT=53 LEN=42 
2026-02-09T17:46:59.861079+01:00 vmi2763474 python3[89252]: ansible-ansible.legacy.command Invoked with _raw_params=find / -xdev -type d -perm -0002 2>/dev/null | wc -l#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:02.381474+01:00 vmi2763474 python3[89280]: ansible-ansible.legacy.command Invoked with _raw_params=find / -xdev -type d -perm -0002 2>/dev/null | head -n 50#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:05.128782+01:00 vmi2763474 python3[89330]: ansible-ansible.legacy.stat Invoked with path=output/localhost/2026-02-09/security_baseline.txt follow=False get_checksum=True checksum_algorithm=sha1 get_mime=True get_attributes=True
2026-02-09T17:47:05.476467+01:00 vmi2763474 python3[89342]: ansible-ansible.legacy.copy Invoked with dest=output/localhost/2026-02-09/security_baseline.txt mode=0644 src=/root/.ansible/tmp/ansible-tmp-1770655624.7794914-89309-237760896708092/source _original_basename=tmpoqhj79in follow=False checksum=b4a1bcdcd584a4740880faf10c4381ef8f29f185 backup=False force=True unsafe_writes=False content=NOT_LOGGING_PARAMETER validate=None directory_mode=None remote_src=None local_follow=None owner=None group=None seuser=None serole=None selevel=None setype=None attributes=None
2026-02-09T17:47:06.021011+01:00 vmi2763474 python3[89367]: ansible-ansible.legacy.command Invoked with _raw_params=awk -F: '$3>=1000 && $1!="nobody" {print $1 ":" $3 ":" $7}' /etc/passwd#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:06.480624+01:00 vmi2763474 python3[89394]: ansible-ansible.legacy.command Invoked with _raw_params=awk -F: '$3<1000 {print $1 ":" $3 ":" $7}' /etc/passwd#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:06.980475+01:00 vmi2763474 python3[89421]: ansible-ansible.legacy.command Invoked with _raw_params=getent group 2>/dev/null | head -n 200 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:07.526533+01:00 vmi2763474 python3[89449]: ansible-ansible.legacy.command Invoked with _raw_params=last -n 50 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:08.274019+01:00 vmi2763474 python3[89480]: ansible-ansible.legacy.stat Invoked with path=output/localhost/2026-02-09/user_audit.txt follow=False get_checksum=True checksum_algorithm=sha1 get_mime=True get_attributes=True
2026-02-09T17:47:08.589514+01:00 vmi2763474 python3[89492]: ansible-ansible.legacy.copy Invoked with dest=output/localhost/2026-02-09/user_audit.txt mode=0644 src=/root/.ansible/tmp/ansible-tmp-1770655627.9065635-89459-226289290122520/source _original_basename=tmp1b9v_syp follow=False checksum=9a6dd8a5919219786aff322ba64962bb5a288884 backup=False force=True unsafe_writes=False content=NOT_LOGGING_PARAMETER validate=None directory_mode=None remote_src=None local_follow=None owner=None group=None seuser=None serole=None selevel=None setype=None attributes=None
2026-02-09T17:47:09.063496+01:00 vmi2763474 python3[89519]: ansible-ansible.legacy.command Invoked with _raw_params=if [ -f /var/log/auth.log ]; then echo /var/log/auth.log; elif [ -f /var/log/secure ]; then echo /var/log/secure; else echo NONE; fi#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:09.528688+01:00 vmi2763474 python3[89545]: ansible-ansible.legacy.command Invoked with _raw_params=if [ "/var/log/auth.log" = "NONE" ]; then echo "Auth log not found"; else tail -n 100 "/var/log/auth.log"; fi#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:10.154668+01:00 vmi2763474 python3[89577]: ansible-ansible.legacy.stat Invoked with path=output/localhost/2026-02-09/auth_audit.txt follow=False get_checksum=True checksum_algorithm=sha1 get_mime=True get_attributes=True
2026-02-09T17:47:10.489821+01:00 vmi2763474 python3[89589]: ansible-ansible.legacy.copy Invoked with dest=output/localhost/2026-02-09/auth_audit.txt mode=0644 src=/root/.ansible/tmp/ansible-tmp-1770655629.8672483-89556-150797999033688/source _original_basename=tmp5t6gm6wy follow=False checksum=393ec21bbf16703877b9b790e79f71907d8d1638 backup=False force=True unsafe_writes=False content=NOT_LOGGING_PARAMETER validate=None directory_mode=None remote_src=None local_follow=None owner=None group=None seuser=None serole=None selevel=None setype=None attributes=None
2026-02-09T17:47:11.032043+01:00 vmi2763474 python3[89615]: ansible-ansible.legacy.command Invoked with _raw_params=ip -brief addr 2>/dev/null || ifconfig -a 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:11.482130+01:00 vmi2763474 python3[89642]: ansible-ansible.legacy.command Invoked with _raw_params=ip route 2>/dev/null || route -n 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:12.031226+01:00 vmi2763474 python3[89671]: ansible-ansible.legacy.command Invoked with _raw_params=cat /etc/resolv.conf 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:12.583077+01:00 vmi2763474 python3[89698]: ansible-ansible.legacy.command Invoked with _raw_params=ufw status 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:13.031056+01:00 vmi2763474 python3[89726]: ansible-ansible.legacy.command Invoked with _raw_params=firewall-cmd --state 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:13.488733+01:00 vmi2763474 python3[89752]: ansible-ansible.legacy.command Invoked with _raw_params=iptables -S 2>/dev/null | head -n 200 || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:14.067788+01:00 vmi2763474 python3[89780]: ansible-ansible.legacy.command Invoked with _raw_params=nft list ruleset 2>/dev/null | head -n 200 || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:14.665860+01:00 vmi2763474 python3[89811]: ansible-ansible.legacy.stat Invoked with path=output/localhost/2026-02-09/network_audit.txt follow=False get_checksum=True checksum_algorithm=sha1 get_mime=True get_attributes=True
2026-02-09T17:47:15.005230+01:00 vmi2763474 python3[89823]: ansible-ansible.legacy.copy Invoked with dest=output/localhost/2026-02-09/network_audit.txt mode=0644 src=/root/.ansible/tmp/ansible-tmp-1770655634.3641458-89790-268353890458118/source _original_basename=tmp258xhhlz follow=False checksum=f42d93204624963d964a007200447e753b7d54db backup=False force=True unsafe_writes=False content=NOT_LOGGING_PARAMETER validate=None directory_mode=None remote_src=None local_follow=None owner=None group=None seuser=None serole=None selevel=None setype=None attributes=None
2026-02-09T17:47:15.442449+01:00 vmi2763474 python3[89848]: ansible-ansible.legacy.command Invoked with _raw_params=timedatectl status 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:15.466001+01:00 vmi2763474 dbus-daemon[857]: [system] Activating via systemd: service name='org.freedesktop.timedate1' unit='dbus-org.freedesktop.timedate1.service' requested by ':1.131' (uid=0 pid=89868 comm="timedatectl status" label="unconfined")
2026-02-09T17:47:15.498417+01:00 vmi2763474 systemd[1]: Starting systemd-timedated.service - Time & Date Service...
2026-02-09T17:47:15.581053+01:00 vmi2763474 dbus-daemon[857]: [system] Successfully activated service 'org.freedesktop.timedate1'
2026-02-09T17:47:15.581916+01:00 vmi2763474 systemd[1]: Started systemd-timedated.service - Time & Date Service.
2026-02-09T17:47:16.055810+01:00 vmi2763474 python3[89894]: ansible-ansible.legacy.command Invoked with _raw_params=chronyc tracking 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:16.515918+01:00 vmi2763474 python3[89920]: ansible-ansible.legacy.command Invoked with _raw_params=ntpq -p 2>/dev/null || true _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:17.088467+01:00 vmi2763474 python3[89949]: ansible-ansible.legacy.stat Invoked with path=output/localhost/2026-02-09/time_sync.txt follow=False get_checksum=True checksum_algorithm=sha1 get_mime=True get_attributes=True
2026-02-09T17:47:17.423290+01:00 vmi2763474 python3[89961]: ansible-ansible.legacy.copy Invoked with dest=output/localhost/2026-02-09/time_sync.txt mode=0644 src=/root/.ansible/tmp/ansible-tmp-1770655636.7878244-89928-158222199027596/source _original_basename=tmpf88tq4ax follow=False checksum=b4c0b9756ce8f219280fd4223b8d00c6bf1365e0 backup=False force=True unsafe_writes=False content=NOT_LOGGING_PARAMETER validate=None directory_mode=None remote_src=None local_follow=None owner=None group=None seuser=None serole=None selevel=None setype=None attributes=None
2026-02-09T17:47:17.957440+01:00 vmi2763474 python3[89989]: ansible-ansible.legacy.command Invoked with _raw_params=sshd -T 2>/dev/null | grep -E '^(permitrootlogin|passwordauthentication|permitemptypasswords)' _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:18.424691+01:00 vmi2763474 python3[90016]: ansible-ansible.legacy.command Invoked with _raw_params=grep -E '^(PASS_MAX_DAYS|PASS_MIN_DAYS|PASS_WARN_AGE)' /etc/login.defs 2>/dev/null | awk '{print $1 "=" $2}'#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:18.749718+01:00 vmi2763474 kernel: [UFW BLOCK] IN=eth0 OUT= MAC=00:50:56:5c:80:c1:c0:69:11:cd:0e:db:08:00 SRC=2.16.105.72 DST=178.18.253.157 LEN=66 TOS=0x00 PREC=0x00 TTL=23 ID=0 PROTO=UDP SPT=62679 DPT=53 LEN=46 
2026-02-09T17:47:18.949261+01:00 vmi2763474 python3[90044]: ansible-ansible.legacy.command Invoked with _raw_params=sysctl net.ipv4.conf.all.accept_source_route net.ipv4.conf.default.accept_source_route net.ipv4.conf.all.accept_redirects net.ipv4.conf.default.accept_redirects 2>/dev/null || true#012 _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
2026-02-09T17:47:19.691695+01:00 vmi2763474 python3[90074]: ansible-ansible.legacy.stat Invoked with path=output/localhost/2026-02-09/compliance_cis.txt follow=False get_checksum=True checksum_algorithm=sha1 get_mime=True get_attributes=True
2026-02-09T17:47:20.023600+01:00 vmi2763474 python3[90086]: ansible-ansible.legacy.copy Invoked with dest=output/localhost/2026-02-09/compliance_cis.txt mode=0644 src=/root/.ansible/tmp/ansible-tmp-1770655639.3648155-90053-122339444225370/source _original_basename=tmpn6_owx22 follow=False checksum=ebc6c02e47536ad44eee6bd7355bdf1fa7c77afd backup=False force=True unsafe_writes=False content=NOT_LOGGING_PARAMETER validate=None directory_mode=None remote_src=None local_follow=None owner=None group=None seuser=None serole=None selevel=None setype=None attributes=None
2026-02-09T17:47:21.331831+01:00 vmi2763474 python3[90119]: ansible-ansible.legacy.command Invoked with _raw_params=tail -50 /var/log/syslog _uses_shell=True expand_argument_vars=True stdin_add_newline=True strip_empty_ends=True argv=None chdir=None executable=None creates=None removes=None stdin=None
```
### updates_readonly.txt
```
Package Manager: apt
Updates:
base-files/noble-updates 13ubuntu10.4 amd64 [upgradable from: 13ubuntu10.3]\ninitramfs-tools-bin/noble-updates 0.142ubuntu25.8 amd64 [upgradable from: 0.142ubuntu25.5]\ninitramfs-tools-core/noble-updates 0.142ubuntu25.8 all [upgradable from: 0.142ubuntu25.5]\ninitramfs-tools/noble-updates 0.142ubuntu25.8 all [upgradable from: 0.142ubuntu25.5]\nmotd-news-config/noble-updates 13ubuntu10.4 all [upgradable from: 13ubuntu10.3]
```
### ai_analysis.txt - NOT FOUND

## AI Analysis
*AI analysis not available.*

## Recommendations

- Review any findings and address high-risk items first.
- Validate service statuses for inactive or failed units.
- Apply security updates when appropriate.
- Consider feeding metrics into monitoring (Prometheus textfile collector).

---
*Generated by ops-snapshot-audit toolkit*
